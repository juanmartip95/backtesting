{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b21ba612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame (first 5 rows):\n",
      "        date                        title_article named_entity  sentiment\n",
      "0 2023-01-01  Tech giant announces record profits        Apple        0.8\n",
      "1 2023-01-01    New regulations hit energy sector   ExxonMobil       -0.7\n",
      "2 2023-01-01   Healthcare startup secures funding      Teladoc        0.5\n",
      "3 2023-01-02     Market optimistic on tech stocks        Apple        0.6\n",
      "4 2023-01-02  Oil prices surge on supply concerns   ExxonMobil        0.4\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "# Uncomment the line below if you don't have the 'punkt' tokenizer data\n",
    "# nltk.download('punkt')\n",
    "# from nltk.tokenize import word_tokenize\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# --- 1. Data Loading (Mock Data Generation) ---\n",
    "# In a real scenario, you would load your CSV file like this:\n",
    "# price = pd.read_csv('your_financial_news_data.csv')\n",
    "\n",
    "# For demonstration, let's create a mock DataFrame similar to your CSV structure.\n",
    "data = {\n",
    "    'date': pd.to_datetime([\n",
    "        '2023-01-01', '2023-01-01', '2023-01-01', '2023-01-02', '2023-01-02',\n",
    "        '2023-01-02', '2023-01-03', '2023-01-03', '2023-01-03', '2023-01-04',\n",
    "        '2023-01-04', '2023-01-04', '2023-01-05', '2023-01-05', '2023-01-05',\n",
    "        '2023-01-06', '2023-01-06', '2023-01-06', '2023-01-07', '2023-01-07',\n",
    "        '2023-01-07', '2023-01-08', '2023-01-08', '2023-01-08', '2023-01-09',\n",
    "        '2023-01-09', '2023-01-09', '2023-01-10', '2023-01-10', '2023-01-10',\n",
    "        '2023-01-11', '2023-01-11', '2023-01-11', '2023-01-12', '2023-01-12',\n",
    "        '2023-01-12', '2023-01-13', '2023-01-13', '2023-01-13', '2023-01-14',\n",
    "        '2023-01-14', '2023-01-14', '2023-01-15', '2023-01-15', '2023-01-15',\n",
    "    ]),\n",
    "    'title_article': [\n",
    "        \"Tech giant announces record profits\", \"New regulations hit energy sector\", \"Healthcare startup secures funding\",\n",
    "        \"Market optimistic on tech stocks\", \"Oil prices surge on supply concerns\", \"Biotech breakthrough unveiled\",\n",
    "        \"Tech stocks show slight dip\", \"Energy sector faces headwinds\", \"Healthcare mergers on the rise\",\n",
    "        \"Tech innovation drives growth\", \"OPEC+ decision impacts oil\", \"Pharma company in clinical trials\",\n",
    "        \"Major tech acquisition hinted\", \"Renewable energy gains traction\", \"Healthcare policy changes discussed\",\n",
    "        \"Tech earnings surprise positively\", \"Gas prices stabilize\", \"Medical device approval expected\",\n",
    "        \"Tech sector sees further gains\", \"Energy stocks rebound\", \"Healthcare costs under scrutiny\",\n",
    "        \"Another tech acquisition\", \"Oil production cut\", \"New drug approval\",\n",
    "        \"Tech valuations questioned\", \"Geopolitical tensions in oil markets\", \"Hospital chain expands\",\n",
    "        \"Chip shortage impacts tech\", \"Green energy investments soar\", \"Telemedicine booming\",\n",
    "        \"Big Tech faces antitrust probe\", \"Coal industry struggles\", \"Vaccine trials show promise\",\n",
    "        \"AI advancements in tech\", \"Solar energy capacity grows\", \"Drug pricing debates\",\n",
    "        \"Social media company under fire\", \"Oil price volatility continues\", \"Mental health services grow\",\n",
    "        \"Metaverse focus for tech\", \"Natural gas demand spikes\", \"Genomic research progress\",\n",
    "        \"Cloud computing strong\", \"Commodity prices soften\", \"Insurance company reports loss\",\n",
    "    ],\n",
    "    'named_entity': [\n",
    "        'Apple', 'ExxonMobil', 'Teladoc', 'Apple', 'ExxonMobil', 'Teladoc',\n",
    "        'Apple', 'ExxonMobil', 'Teladoc', 'Apple', 'ExxonMobil', 'Teladoc',\n",
    "        'Apple', 'ExxonMobil', 'Teladoc', 'Apple', 'ExxonMobil', 'Teladoc',\n",
    "        'Apple', 'ExxonMobil', 'Teladoc', 'Apple', 'ExxonMobil', 'Teladoc',\n",
    "        'Apple', 'ExxonMobil', 'Teladoc', 'Apple', 'ExxonMobil', 'Teladoc',\n",
    "        'Apple', 'ExxonMobil', 'Teladoc', 'Apple', 'ExxonMobil', 'Teladoc',\n",
    "        'Apple', 'ExxonMobil', 'Teladoc', 'Apple', 'ExxonMobil', 'Teladoc',\n",
    "        'Apple', 'ExxonMobil', 'Teladoc',\n",
    "    ],\n",
    "    # Sentiment scores ranging from -1 (very negative) to 1 (very positive)\n",
    "    'sentiment': [\n",
    "        0.8, -0.7, 0.5, 0.6, 0.4, 0.7, 0.1, -0.2, 0.6, 0.7, -0.1, 0.8,\n",
    "        0.9, 0.6, 0.3, 0.95, 0.0, 0.85, 0.8, 0.5, -0.1, 0.9, -0.8, 0.9,\n",
    "        -0.3, -0.6, 0.7, -0.9, 0.8, 0.9, -0.7, -0.9, 0.95, 0.8, 0.7, -0.2,\n",
    "        -0.6, 0.1, 0.5, 0.7, 0.6, 0.85, 0.8, 0.3, -0.4,\n",
    "    ]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"Original DataFrame (first 5 rows):\")\n",
    "print(df.head())\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "845bdf4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daily Average Sentiment per Entity (first 5 rows):\n",
      "        date named_entity  sentiment\n",
      "0 2023-01-01        Apple        0.8\n",
      "1 2023-01-02        Apple        0.6\n",
      "2 2023-01-03        Apple        0.1\n",
      "3 2023-01-04        Apple        0.7\n",
      "4 2023-01-05        Apple        0.9\n",
      "\n",
      "==================================================\n",
      "\n",
      "Daily Sentiment with Rolling Averages, Std Dev, and Shift Flags (first 15 rows for one entity):\n",
      "         date named_entity  sentiment  rolling_avg_sentiment_7d  \\\n",
      "0  2023-01-01        Apple       0.80                       NaN   \n",
      "1  2023-01-02        Apple       0.60                       NaN   \n",
      "2  2023-01-03        Apple       0.10                       NaN   \n",
      "3  2023-01-04        Apple       0.70                       NaN   \n",
      "4  2023-01-05        Apple       0.90              6.200000e-01   \n",
      "5  2023-01-06        Apple       0.95              6.750000e-01   \n",
      "6  2023-01-07        Apple       0.80              6.928571e-01   \n",
      "7  2023-01-08        Apple       0.90              7.071429e-01   \n",
      "8  2023-01-09        Apple      -0.30              5.785714e-01   \n",
      "9  2023-01-10        Apple      -0.90              4.357143e-01   \n",
      "10 2023-01-11        Apple      -0.70              2.357143e-01   \n",
      "11 2023-01-12        Apple       0.80              2.214286e-01   \n",
      "12 2023-01-13        Apple      -0.60              3.172066e-17   \n",
      "13 2023-01-14        Apple       0.70             -1.428571e-02   \n",
      "14 2023-01-15        Apple       0.80             -2.857143e-02   \n",
      "\n",
      "    rolling_std_sentiment_30d  deviation  sentiment_shift  \n",
      "0                         NaN        NaN                0  \n",
      "1                         NaN        NaN                0  \n",
      "2                         NaN        NaN                0  \n",
      "3                         NaN        NaN                0  \n",
      "4                         NaN   0.280000                0  \n",
      "5                         NaN   0.275000                0  \n",
      "6                         NaN   0.107143                0  \n",
      "7                         NaN   0.192857                0  \n",
      "8                         NaN   0.878571                0  \n",
      "9                    0.622919   1.335714                1  \n",
      "10                   0.685930   0.935714                0  \n",
      "11                   0.666785   0.578571                0  \n",
      "12                   0.694668   0.600000                0  \n",
      "13                   0.675442   0.714286                0  \n",
      "14                   0.661654   0.828571                0  \n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Detecting a \"Sentiment Shift\" ---\n",
    "\n",
    "# Aggregate daily sentiment for each named entity\n",
    "daily_sentiment = df.groupby(['date', 'named_entity'])['sentiment'].mean().reset_index()\n",
    "daily_sentiment = daily_sentiment.sort_values(by=['named_entity', 'date']).reset_index(drop=True)\n",
    "\n",
    "print(\"Daily Average Sentiment per Entity (first 5 rows):\")\n",
    "print(daily_sentiment.head())\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Calculate rolling average and rolling standard deviation for sentiment\n",
    "# These help us understand the typical sentiment and its variability over time.\n",
    "# We'll use a 7-day rolling window for the average and a 30-day window for standard deviation.\n",
    "# min_periods ensures we only calculate when enough data points are available.\n",
    "\n",
    "# Calculate rolling average sentiment\n",
    "daily_sentiment['rolling_avg_sentiment_7d'] = daily_sentiment.groupby('named_entity')['sentiment'] \\\n",
    "                                                    .rolling(window=7, min_periods=5).mean().reset_index(level=0, drop=True)\n",
    "\n",
    "# Calculate rolling standard deviation of sentiment\n",
    "daily_sentiment['rolling_std_sentiment_30d'] = daily_sentiment.groupby('named_entity')['sentiment'] \\\n",
    "                                                    .rolling(window=30, min_periods=10).std().reset_index(level=0, drop=True)\n",
    "\n",
    "# Define a threshold for detecting a \"shift\"\n",
    "# A shift is detected if the current daily sentiment deviates from the rolling average\n",
    "# by more than a certain number of standard deviations.\n",
    "# We'll use 1.5 standard deviations as a threshold for demonstration.\n",
    "std_dev_threshold = 1.5\n",
    "\n",
    "# Calculate the deviation from the rolling average\n",
    "daily_sentiment['deviation'] = abs(daily_sentiment['sentiment'] - daily_sentiment['rolling_avg_sentiment_7d'])\n",
    "\n",
    "# Flag a sentiment shift if deviation is above the threshold * rolling_std_sentiment_30d\n",
    "daily_sentiment['sentiment_shift'] = np.where(\n",
    "    (daily_sentiment['deviation'] > (std_dev_threshold * daily_sentiment['rolling_std_sentiment_30d'])) &\n",
    "    (daily_sentiment['rolling_std_sentiment_30d'].notna()), # Ensure rolling std is not NaN\n",
    "    1, # Indicates a shift\n",
    "    0  # No shift\n",
    ")\n",
    "\n",
    "print(f\"Daily Sentiment with Rolling Averages, Std Dev, and Shift Flags (first 15 rows for one entity):\")\n",
    "# Filter for a specific entity to better visualize the rolling calculations\n",
    "print(daily_sentiment[daily_sentiment['named_entity'] == 'Apple'].head(15))\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e9745ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Risk Indicator Calculation (first 15 rows for 'Apple'):\n",
      "         date  sentiment  rolling_avg_sentiment_7d  sentiment_shift  \\\n",
      "0  2023-01-01       0.80                       NaN                0   \n",
      "1  2023-01-02       0.60                       NaN                0   \n",
      "2  2023-01-03       0.10                       NaN                0   \n",
      "3  2023-01-04       0.70                       NaN                0   \n",
      "4  2023-01-05       0.90              6.200000e-01                0   \n",
      "5  2023-01-06       0.95              6.750000e-01                0   \n",
      "6  2023-01-07       0.80              6.928571e-01                0   \n",
      "7  2023-01-08       0.90              7.071429e-01                0   \n",
      "8  2023-01-09      -0.30              5.785714e-01                0   \n",
      "9  2023-01-10      -0.90              4.357143e-01                1   \n",
      "10 2023-01-11      -0.70              2.357143e-01                0   \n",
      "11 2023-01-12       0.80              2.214286e-01                0   \n",
      "12 2023-01-13      -0.60              3.172066e-17                0   \n",
      "13 2023-01-14       0.70             -1.428571e-02                0   \n",
      "14 2023-01-15       0.80             -2.857143e-02                0   \n",
      "\n",
      "    risk_indicator  \n",
      "0            0.100  \n",
      "1            0.200  \n",
      "2            0.450  \n",
      "3            0.150  \n",
      "4            0.050  \n",
      "5            0.025  \n",
      "6            0.100  \n",
      "7            0.050  \n",
      "8            0.650  \n",
      "9            1.450  \n",
      "10           0.850  \n",
      "11           0.100  \n",
      "12           0.800  \n",
      "13           0.150  \n",
      "14           0.100  \n",
      "\n",
      "==================================================\n",
      "\n",
      "Further Considerations for a Real-World Scenario:\n",
      "\n",
      "1.  **Data Quality & Granularity:** Real financial news data requires robust cleaning, deduplication, and often involves much higher frequency (e.g., intraday).\n",
      "2.  **Advanced NLP:**\n",
      "    * **Named Entity Recognition (NER) refinement:** Ensuring 'named_entity' accurately maps to publicly traded companies/sectors.\n",
      "    * **Contextual Sentiment:** Differentiating sentiment about a company vs. general market sentiment within an article. Models like FinBERT or other financial-specific LLMs would be crucial.\n",
      "    * **Event Detection:** Identifying specific events (e.g., earnings calls, product launches, lawsuits) that trigger sentiment changes.\n",
      "3.  **Sophisticated Shift Detection:**\n",
      "    * Statistical tests (e.g., CUSUM, EWMA charts) to detect statistically significant changes in time series data.\n",
      "    * Machine learning models trained to classify \"shift\" events based on various features.\n",
      "4.  **Risk Indicator Refinement:**\n",
      "    * **Integration with Financial Data:** Incorporating stock price volatility, trading volume, credit default swap (CDS) spreads, implied volatility from options, etc.\n",
      "    * **Sector/Industry Averages:** Comparing a company's sentiment shift to its peers or sector average.\n",
      "    * **Forward-Looking Measures:** Attempting to predict future sentiment or risk based on current shifts.\n",
      "    * **Backtesting:** Rigorous backtesting of the risk indicator against actual market outcomes (e.g., drawdowns, large price movements).\n",
      "    * **Thresholds:** Dynamically adjusting thresholds for 'shift' detection based on market conditions or entity-specific characteristics.\n",
      "5.  **Causality:** Understanding *why* a sentiment shift occurred. Is it due to fundamental news or market noise?\n",
      "6.  **Human-in-the-Loop:** For high-stakes decisions, human analysts often review flagged sentiment shifts.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- 4. Integrating the Signal into a \"Risk Indicator\" ---\n",
    "\n",
    "# A risk indicator should quantify potential negative impact or uncertainty.\n",
    "# Here's a simple conceptual approach:\n",
    "# We'll combine the sentiment shift (sudden change) with the absolute sentiment level.\n",
    "# For example, a sharp drop in sentiment (negative shift) or a consistently low sentiment\n",
    "# could indicate higher risk. A sharp positive shift might also indicate higher risk\n",
    "# due to increased volatility/speculation, or it could be seen as a positive development.\n",
    "# For simplicity, let's consider *any* significant shift (positive or negative) as increasing risk.\n",
    "# And a very low absolute sentiment score as increasing risk.\n",
    "\n",
    "# Normalize sentiment to be between 0 and 1, where 0 is most negative and 1 is most positive.\n",
    "# Then, we can derive a 'sentiment risk' where lower sentiment values increase risk.\n",
    "daily_sentiment['normalized_sentiment'] = (daily_sentiment['sentiment'] + 1) / 2\n",
    "\n",
    "# Calculate a simple 'Sentiment-driven Risk Score'\n",
    "# This is a conceptual score. In a real scenario, this would be much more complex,\n",
    "# potentially involving financial metrics, market volatility, etc.\n",
    "\n",
    "# Components of the risk score:\n",
    "# 1. Base Risk from Sentiment: Lower sentiment implies higher risk. Max score when sentiment is -1.\n",
    "#    We'll invert the normalized sentiment: 1 - normalized_sentiment.\n",
    "#    So, if sentiment is -1 (normalized 0), risk_sentiment_component is 1.\n",
    "#    If sentiment is 1 (normalized 1), risk_sentiment_component is 0.\n",
    "daily_sentiment['risk_sentiment_component'] = 1 - daily_sentiment['normalized_sentiment']\n",
    "\n",
    "# 2. Shift Risk: A sudden sentiment shift (flagged as 1) adds to risk.\n",
    "#    We'll multiply the sentiment_shift flag by a weight (e.g., 0.5) to indicate its impact.\n",
    "shift_weight = 0.5\n",
    "daily_sentiment['risk_shift_component'] = daily_sentiment['sentiment_shift'] * shift_weight\n",
    "\n",
    "# Total Risk Indicator: Sum of components.\n",
    "# This score will be higher when sentiment is low, or when there's a significant shift.\n",
    "daily_sentiment['risk_indicator'] = daily_sentiment['risk_sentiment_component'] + daily_sentiment['risk_shift_component']\n",
    "\n",
    "print(\"Risk Indicator Calculation (first 15 rows for 'Apple'):\")\n",
    "print(daily_sentiment[daily_sentiment['named_entity'] == 'Apple'][['date', 'sentiment', 'rolling_avg_sentiment_7d', 'sentiment_shift', 'risk_indicator']].head(15))\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# --- Further Considerations for a Real-World Scenario ---\n",
    "\n",
    "print(\"Further Considerations for a Real-World Scenario:\")\n",
    "print(\"\"\"\n",
    "1.  **Data Quality & Granularity:** Real financial news data requires robust cleaning, deduplication, and often involves much higher frequency (e.g., intraday).\n",
    "2.  **Advanced NLP:**\n",
    "    * **Named Entity Recognition (NER) refinement:** Ensuring 'named_entity' accurately maps to publicly traded companies/sectors.\n",
    "    * **Contextual Sentiment:** Differentiating sentiment about a company vs. general market sentiment within an article. Models like FinBERT or other financial-specific LLMs would be crucial.\n",
    "    * **Event Detection:** Identifying specific events (e.g., earnings calls, product launches, lawsuits) that trigger sentiment changes.\n",
    "3.  **Sophisticated Shift Detection:**\n",
    "    * Statistical tests (e.g., CUSUM, EWMA charts) to detect statistically significant changes in time series data.\n",
    "    * Machine learning models trained to classify \"shift\" events based on various features.\n",
    "4.  **Risk Indicator Refinement:**\n",
    "    * **Integration with Financial Data:** Incorporating stock price volatility, trading volume, credit default swap (CDS) spreads, implied volatility from options, etc.\n",
    "    * **Sector/Industry Averages:** Comparing a company's sentiment shift to its peers or sector average.\n",
    "    * **Forward-Looking Measures:** Attempting to predict future sentiment or risk based on current shifts.\n",
    "    * **Backtesting:** Rigorous backtesting of the risk indicator against actual market outcomes (e.g., drawdowns, large price movements).\n",
    "    * **Thresholds:** Dynamically adjusting thresholds for 'shift' detection based on market conditions or entity-specific characteristics.\n",
    "5.  **Causality:** Understanding *why* a sentiment shift occurred. Is it due to fundamental news or market noise?\n",
    "6.  **Human-in-the-Loop:** For high-stakes decisions, human analysts often review flagged sentiment shifts.\n",
    "\"\"\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
