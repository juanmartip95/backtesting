{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d577cfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data Structures Practice Exercises\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from collections import defaultdict, Counter, deque\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76c18046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def process_numbers(nums):\n",
    "        # YOUR CODE HERE\n",
    "    result = []\n",
    "    for n in nums:\n",
    "        if n % 2 == 0:\n",
    "            result.append(2*n)\n",
    "        else:\n",
    "            result.append(n)\n",
    "    return result\n",
    "\n",
    "process_numbers((1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35e6834e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'alice': 80, 'bob': -110, 'charlie': 200}, ['bob'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def analyze_transactions(transactions):\n",
    "        # YOUR CODE HERE\n",
    "        user_totals = defaultdict(int)\n",
    "        for user, amount in transactions:\n",
    "            user_totals[user] += amount\n",
    "        \n",
    "        negative_users = [user for user, total in user_totals.items() if total < 0]\n",
    "        \n",
    "        return dict(user_totals), negative_users\n",
    "\n",
    "            \n",
    "analyze_transactions(transactions = [\n",
    "        ('alice', 100), ('bob', -50), ('alice', -30), \n",
    "        ('charlie', 200), ('bob', -60), ('alice', 10)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b593239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'hello world programming' -> {'most_frequent_char': 'l', 'longest_word': 'programming', 'vowel_count': 6}\n",
      "'The quick brown fox jumps over the lazy dog' -> {'most_frequent_char': 'o', 'longest_word': 'quick', 'vowel_count': 11}\n",
      "'Python is awesome for data manipulation' -> {'most_frequent_char': 'a', 'longest_word': 'manipulation', 'vowel_count': 15}\n"
     ]
    }
   ],
   "source": [
    "def analyze_string(text):\n",
    "        # YOUR CODE HERE\n",
    "        # Most frequent character (excluding spaces)\n",
    "        char_count = Counter(char.lower() for char in text if char != ' ')\n",
    "        most_frequent = char_count.most_common(1)[0][0] if char_count else ''\n",
    "        \n",
    "        # Longest word\n",
    "        words = text.split()\n",
    "        longest_word = max(words, key=len) if words else ''\n",
    "        \n",
    "        # Vowel count\n",
    "        vowels = set('aeiouAEIOU')\n",
    "        vowel_count = sum(1 for char in text if char in vowels)\n",
    "        \n",
    "        return {\n",
    "            'most_frequent_char': most_frequent,\n",
    "            'longest_word': longest_word,\n",
    "            'vowel_count': vowel_count\n",
    "        }\n",
    "    \n",
    "    # Test cases\n",
    "test_strings = [\"hello world programming\", \"The quick brown fox jumps over the lazy dog\", \"Python is awesome for data manipulation\"]\n",
    "    \n",
    "for text in test_strings:\n",
    "     result = analyze_string(text)\n",
    "     print(f\"'{text}' -> {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdb12d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pattern 1: Array/List Manipulation\n",
    "#Question: \"Find all pairs in an array that sum to a target value.\"\n",
    "\n",
    "def two_sum(nums, target):\n",
    "    seen = {}\n",
    "    for i, num in enumerate(nums):\n",
    "        complement = target - num\n",
    "        if complement in seen:\n",
    "            return [seen[complement], i]\n",
    "        seen[num] = i\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2e9e80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pattern 2: String Processing\n",
    "#Question: \"Check if two strings are anagrams\n",
    "def is_anagram(s1, s2):\n",
    "    return Counter(s1) == Counter(s2)\n",
    "    # Alternative: return sorted(s1) == sorted(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "238d78ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pattern 3: Hash Table Grouping\n",
    "#Question: \"Group words by their length.\"\n",
    "def group_by_length(words):\n",
    "    groups = defaultdict(list)\n",
    "    for word in words:\n",
    "        groups[len(word)].append(word)\n",
    "    return dict(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35155c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def analyze_sentiment_data(csv_path):\n",
    "    # Read the CSV file\n",
    "    data = pd.read_csv(csv_path)\n",
    "\n",
    "    # Extract the 'name' and 'sentiment' columns\n",
    "    name_sentiment_data = data[['name', 'sentiment']]\n",
    "\n",
    "    # Group by 'name' and calculate the average sentiment and count of appearances\n",
    "    grouped_data = name_sentiment_data.groupby('name').agg(\n",
    "        average_sentiment=('sentiment', 'mean'),\n",
    "        appearances=('sentiment', 'count')\n",
    "    ).reset_index()\n",
    "\n",
    "    # Find the name with the most appearances\n",
    "    most_appearances = grouped_data.loc[grouped_data['appearances'].idxmax()]\n",
    "\n",
    "    # Find the name with the lowest average sentiment\n",
    "    lowest_avg_sentiment = grouped_data.loc[grouped_data['average_sentiment'].idxmin()]\n",
    "\n",
    "    return {\n",
    "        'average_sentiments': dict(zip(grouped_data['name'], grouped_data['average_sentiment'])),\n",
    "        'most_appearances': most_appearances['name'],\n",
    "        'lowest_avg_sentiment': (lowest_avg_sentiment['name'], lowest_avg_sentiment['average_sentiment'])\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "# result = analyze_sentiment_data('path_to_your_csv_file.csv')\n",
    "# print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f37550c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Given a CSV of daily stock prices, calculate the 7-day moving average for each stock.\n",
    "def calculate_moving_average(prices_dict, window=7):\n",
    "    result = {}\n",
    "    for stock, prices in prices_dict.items():\n",
    "        if len(prices) < window:\n",
    "            result[stock] = []\n",
    "            continue\n",
    "        moving_avg = []\n",
    "        for i in range(window-1, len(prices)):\n",
    "            avg = sum(prices[i-window+1:i+1]) / window\n",
    "            moving_avg.append(avg)\n",
    "        result[stock] = moving_avg\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8bfb4ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Given a dictionary of portfolio weights, validate that they sum to 1.0 and no weight exceeds 50%.\n",
    "def validate_portfolio(weights):\n",
    "    total = sum(weights.values())\n",
    "    max_weight = max(weights.values())\n",
    "    \n",
    "    errors = []\n",
    "    if abs(total - 1.0) > 1e-6:\n",
    "        errors.append(f\"Weights sum to {total:.6f}, not 1.0\")\n",
    "    if max_weight > 0.5:\n",
    "        errors.append(f\"Maximum weight {max_weight:.3f} exceeds 50%\")\n",
    "    \n",
    "    return len(errors) == 0, errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91b97831",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Given a list of news articles with sentiment scores, group by date and calculate daily average sentiment.\n",
    "def aggregate_sentiment(articles):\n",
    "    # articles = [{'date': '2024-01-01', 'sentiment': 0.8}, ...]\n",
    "    daily_sentiment = defaultdict(list)\n",
    "    \n",
    "    for article in articles:\n",
    "        daily_sentiment[article['date']].append(article['sentiment'])\n",
    "    \n",
    "    return {\n",
    "        date: sum(scores) / len(scores) \n",
    "        for date, scores in daily_sentiment.items()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02ba40bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def backtest_moving_avg(prices_csv):\n",
    "    df = pd.read_csv(prices_csv, parse_dates=['date'])\n",
    "    df = df.sort_values('date').set_index('date')\n",
    "    df['SMA5'] = df['close_price'].rolling(window=5).mean()\n",
    "    df['SMA20'] = df['close_price'].rolling(window=20).mean()\n",
    "\n",
    "    # Create signal: 1 if SMA5 > SMA20, 0 otherwise\n",
    "    df['signal'] = np.where(df['SMA5'] > df['SMA20'], 1, 0)\n",
    "    # Generate trading signal: buy (1) when signal changes from 0 to 1; sell (0) when changes from 1 to 0\n",
    "    df['position'] = df['signal'].diff().fillna(0)\n",
    "    # For simplicity: hold position of +1 when signal==1 else 0\n",
    "    df['hold'] = df['signal'].shift(1).fillna(0)  # We hold at close of previous day\n",
    "    # Compute daily returns\n",
    "    df['returns'] = df['close_price'].pct_change().fillna(0)\n",
    "    # Strategy returns: returns when we are holding\n",
    "    df['strat_returns'] = df['hold'] * df['returns']\n",
    "    # Cumulative return\n",
    "    cumulative = (1 + df['strat_returns']).cumprod() - 1\n",
    "    total_return = cumulative.iloc[-1]\n",
    "    # Sharpe (annualized): mean daily / std daily * sqrt(252)\n",
    "    sharpe = df['strat_returns'].mean() / df['strat_returns'].std(ddof=0) * np.sqrt(252)\n",
    "    return total_return, sharpe, df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91c25003",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(CVXPY) Jun 12 12:21:18 PM: Your problem has 3 variables, 4 constraints, and 0 parameters.\n",
      "(CVXPY) Jun 12 12:21:18 PM: It is compliant with the following grammars: DCP, DQCP\n",
      "(CVXPY) Jun 12 12:21:18 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n",
      "(CVXPY) Jun 12 12:21:18 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n",
      "(CVXPY) Jun 12 12:21:18 PM: Your problem is compiled with the CPP canonicalization backend.\n",
      "(CVXPY) Jun 12 12:21:18 PM: Compiling problem (target solver=ECOS).\n",
      "(CVXPY) Jun 12 12:21:18 PM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> ECOS\n",
      "(CVXPY) Jun 12 12:21:18 PM: Applying reduction Dcp2Cone\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculated Covariance Matrix:\n",
      "          A         B         C\n",
      "A  0.000100 -0.000017 -0.000027\n",
      "B -0.000017  0.000180 -0.000012\n",
      "C -0.000027 -0.000012  0.000095\n",
      "\n",
      "Determinant of covariance matrix: 1.53e-12\n",
      "===============================================================================\n",
      "                                     CVXPY                                     \n",
      "                                     v1.6.6                                    \n",
      "===============================================================================\n",
      "-------------------------------------------------------------------------------\n",
      "                                  Compilation                                  \n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(CVXPY) Jun 12 12:21:18 PM: Applying reduction CvxAttr2Constr\n",
      "(CVXPY) Jun 12 12:21:18 PM: Applying reduction ConeMatrixStuffing\n",
      "(CVXPY) Jun 12 12:21:19 PM: Applying reduction ECOS\n",
      "(CVXPY) Jun 12 12:21:19 PM: Finished problem compilation (took 6.844e-01 seconds).\n",
      "(CVXPY) Jun 12 12:21:19 PM: Invoking solver ECOS  to obtain a solution.\n",
      "(CVXPY) Jun 12 12:21:19 PM: Problem status: optimal\n",
      "(CVXPY) Jun 12 12:21:19 PM: Optimal value: 2.511e-05\n",
      "(CVXPY) Jun 12 12:21:19 PM: Compilation took 6.844e-01 seconds\n",
      "(CVXPY) Jun 12 12:21:19 PM: Solver (including time spent in interface) took 2.102e-03 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "                                Numerical solver                               \n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "ECOS 2.0.10 - (C) embotech GmbH, Zurich Switzerland, 2012-15. Web: www.embotech.com/ECOS\n",
      "\n",
      "It     pcost       dcost      gap   pres   dres    k/t    mu     step   sigma     IR    |   BT\n",
      " 0  +0.000e+00  -2.027e-01  +5e+00  5e-01  6e-01  1e+00  1e+00    ---    ---    1  1  - |  -  - \n",
      " 1  +2.000e-04  -5.566e-02  +7e-01  2e-02  6e-02  7e-03  2e-01  0.9478  7e-02   1  1  1 |  0  0\n",
      " 2  +2.019e-04  -3.505e-04  +9e-03  3e-04  1e-03  2e-04  2e-03  0.9875  2e-03   1  1  1 |  0  0\n",
      " 3  +3.435e-05  +6.484e-06  +5e-04  1e-05  5e-05  6e-06  1e-04  0.9542  5e-04   1  1  1 |  0  0\n",
      " 4  +2.520e-05  +2.283e-05  +4e-05  1e-06  5e-06  1e-06  1e-05  0.9644  7e-02   1  1  1 |  0  0\n",
      " 5  +2.511e-05  +2.508e-05  +6e-07  2e-08  7e-08  2e-08  1e-07  0.9861  1e-04   1  1  1 |  0  0\n",
      " 6  +2.511e-05  +2.511e-05  +4e-08  1e-09  5e-09  1e-09  1e-08  0.9351  4e-04   1  1  1 |  0  0\n",
      " 7  +2.511e-05  +2.511e-05  +4e-09  1e-10  5e-10  1e-10  1e-09  0.9799  8e-02   2  1  1 |  0  0\n",
      "\n",
      "OPTIMAL (within feastol=4.7e-10, reltol=1.6e-04, abstol=3.9e-09).\n",
      "Runtime: 0.001236 seconds.-------------------------------------------------------------------------------\n",
      "                                    Summary                                    \n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Optimal Weights: [0.39441062 0.20424036 0.40134902]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cvxpy as cp\n",
    "\n",
    "def min_var_weights(returns_df):\n",
    "    # --- Debugging Step 1: Check for NaNs in input DataFrame ---\n",
    "    if returns_df.isnull().sum().sum() > 0:\n",
    "        print(\"Warning: Input DataFrame 'returns_df' contains NaN values.\")\n",
    "        print(returns_df.isnull().sum())\n",
    "        # Option 1: Drop NaNs (simplest, but loses data)\n",
    "        returns_df = returns_df.dropna()\n",
    "        # Option 2: Fill NaNs (e.g., with 0 or forward-fill)\n",
    "        # returns_df = returns_df.fillna(0) # or returns_df.fillna(method='ffill')\n",
    "        print(\"NaN values handled by dropping rows with NaNs.\")\n",
    "        if returns_df.empty:\n",
    "            raise ValueError(\"DataFrame became empty after dropping NaNs. Cannot proceed with covariance calculation.\")\n",
    "\n",
    "    cov = returns_df.cov().values  # 3 × 3 covariance\n",
    "\n",
    "    # --- Debugging Step 2: Inspect the covariance matrix ---\n",
    "    print(\"\\nCalculated Covariance Matrix:\")\n",
    "    print(pd.DataFrame(cov, columns=returns_df.columns, index=returns_df.columns))\n",
    "\n",
    "    if np.isnan(cov).any():\n",
    "        raise ValueError(\"Covariance matrix contains NaN values. This usually means there were not enough non-NaN data points for calculation.\")\n",
    "\n",
    "    # A quick check for positive semi-definiteness (more robust checks involve eigenvalues)\n",
    "    # If the determinant is very close to zero, it might indicate singularity\n",
    "    try:\n",
    "        det_cov = np.linalg.det(cov)\n",
    "        print(f\"\\nDeterminant of covariance matrix: {det_cov:.2e}\")\n",
    "        if det_cov < 1e-15: # Arbitrary small threshold\n",
    "            print(\"Warning: Covariance matrix determinant is very small, might be near singular.\")\n",
    "    except np.linalg.LinAlgError:\n",
    "        print(\"Warning: Could not compute determinant, possibly singular matrix.\")\n",
    "\n",
    "\n",
    "    n = cov.shape[0]\n",
    "\n",
    "    # Define optimization variable\n",
    "    w = cp.Variable(n)\n",
    "    # Objective: minimize wᵀ Σ w\n",
    "    risk = cp.quad_form(w, cov)\n",
    "    objective = cp.Minimize(risk)\n",
    "    # Constraints: sum(w)=1, w >= 0\n",
    "    constraints = [cp.sum(w) == 1, w >= 0]\n",
    "\n",
    "    prob = cp.Problem(objective, constraints)\n",
    "\n",
    "    # --- Solution Step 3 & 4: Try a different solver and enable verbose output ---\n",
    "    try:\n",
    "        # Try ECOS, which is generally quite robust.\n",
    "        # verbose=True will print solver output to help diagnose issues.\n",
    "        prob.solve(solver=cp.ECOS, verbose=True)\n",
    "        # If ECOS fails, uncomment the line below to try SCS\n",
    "        # prob.solve(solver=cp.SCS, verbose=True)\n",
    "\n",
    "        if prob.status == cp.OPTIMAL or prob.status == cp.OPTIMAL_INACCURATE:\n",
    "            return w.value  # array of length 3\n",
    "        else:\n",
    "            print(f\"\\nSolver status: {prob.status}\")\n",
    "            print(\"Problem could not be solved optimally.\")\n",
    "            return None # Or raise an error\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn error occurred during solving with ECOS: {e}\")\n",
    "        print(\"Consider trying another solver like cp.SCS or checking your data for issues.\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# --- Main execution ---\n",
    "# Read the CSV, parsing the 'date' column\n",
    "returns_df = pd.read_csv(\n",
    "    \"/workspaces/backtesting/investment-portfolio-project/data/synthetic_portfolio.csv\",\n",
    "    parse_dates=['date']\n",
    ")\n",
    "\n",
    "# Set the 'date' column as the DataFrame's index\n",
    "returns_df.set_index('date', inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "weights = min_var_weights(returns_df.copy()) # Use .copy() to avoid modifying the original DataFrame passed in (good practice)\n",
    "\n",
    "if weights is not None:\n",
    "    print(\"\\nOptimal Weights:\", weights)\n",
    "else:\n",
    "    print(\"\\nCould not determine optimal weights.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22d11201",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def performance_metrics(daily_ret):\n",
    "    # 1. Annualized return: (1 + r_daily).prod()^(252/N) - 1\n",
    "    cumulative = np.prod(1 + daily_ret) - 1\n",
    "    annual_ret = (1 + cumulative) ** (252 / len(daily_ret)) - 1\n",
    "\n",
    "    # 2. Annualized vol: std(daily_ret) * sqrt(252)\n",
    "    annual_vol = np.std(daily_ret, ddof=1) * np.sqrt(252)\n",
    "\n",
    "    # 3. Sharpe (RFR=0): mean(daily_ret)/std(daily_ret) * sqrt(252)\n",
    "    sharpe = np.mean(daily_ret) / np.std(daily_ret, ddof=1) * np.sqrt(252)\n",
    "\n",
    "    return annual_ret, annual_vol, sharpe\n",
    "\n",
    "# Example usage: metrics = performance_metrics(np.array([...]))\n",
    "# print(f\"Ann. Return: {metrics[0]:.2%}, Vol: {metrics[1]:.2%}, Sharpe: {metrics[2]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01f0b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dcba'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# given the following string\n",
    "\n",
    "s = \"abcd\"\n",
    "\n",
    "# write some code that will reverse it: \n",
    "\n",
    "def string_reversal(s: str) -> str:\n",
    "    # your code here! \n",
    "    lst = list(s)\n",
    "    rev=lst[::-1]\n",
    "    return ''.join(rev)   \n",
    "\n",
    "string_reversal(s)  # dcba\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13dc68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a function that converts lists that look like `input_list` into something that looks like `expected_list`. \n",
    "# Assume that any input to `format_list` will take the form of a list comprising strings that have a single underscore.\n",
    "\n",
    "def format_list(li: list[str]) -> list[str]:\n",
    "    # your code here\n",
    "    n=len(li)\n",
    "    for i in range(n):\n",
    "        lr=li[i].split(\"_\")\n",
    "        expected_arr=f\"_{i}_\".join(lr)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "input_list = [\"item_thing\", \"next_item\", \"third_thingie\", \"howard_johnson\"] \n",
    "expected_list = [\"item_0_thing\", \"next_1_item\", \"third_2_thingie\", \"howard_3_johnson\"] \n",
    "test_list = format_list(input_list)\n",
    "assert test_list == expected_list\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
